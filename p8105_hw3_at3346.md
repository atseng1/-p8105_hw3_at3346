p8105\_hw3\_at3346
================
Ashley Tseng
10/14/2019

## Problem 1

Load data:

``` r
data("instacart") 
force(instacart)
```

    ## # A tibble: 1,384,617 x 15
    ##    order_id product_id add_to_cart_ord… reordered user_id eval_set
    ##       <int>      <int>            <int>     <int>   <int> <chr>   
    ##  1        1      49302                1         1  112108 train   
    ##  2        1      11109                2         1  112108 train   
    ##  3        1      10246                3         0  112108 train   
    ##  4        1      49683                4         0  112108 train   
    ##  5        1      43633                5         1  112108 train   
    ##  6        1      13176                6         0  112108 train   
    ##  7        1      47209                7         0  112108 train   
    ##  8        1      22035                8         1  112108 train   
    ##  9       36      39612                1         0   79431 train   
    ## 10       36      19660                2         1   79431 train   
    ## # … with 1,384,607 more rows, and 9 more variables: order_number <int>,
    ## #   order_dow <int>, order_hour_of_day <int>,
    ## #   days_since_prior_order <int>, product_name <chr>, aisle_id <int>,
    ## #   department_id <int>, aisle <chr>, department <chr>

``` r
n_aisle = instacart %>% 
  count(aisle)
```

The `instacart` dataset contains 1384617 observations (representing
products from orders) of 131,209 unique users and 15 variables. There is
a single order per user in this dataset. Key variables in the
`instacart` dataset include `reordered`, which describes if this product
has been ordered by this user in the past,`order_dow`, which describes
the day of the week on which the order was placed, and
`order_hour_of_day`, which describes the hour of the day on which the
order was placed. For example, user \# ordered times…

There are 134 aisles. The aisles that the most items are ordered from
are “fresh vegetables” (150,609 orders) and “fresh fruit” (150,473
orders).

``` r
n_ordered = n_aisle %>% 
  filter(n > 10000) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_bar(stat = "identity", fill = "sea green") +
  coord_flip() +
  labs(
    title = "Number of Items Ordered in Each Aisle",
    x = "Aisle Name",
    y = "Number of Items Ordered") +
  theme(
    legend.position = "none",
    plot.title = element_text(hjust = 0.5),
    text = element_text(size = 5))

n_ordered
```

<img src="p8105_hw3_at3346_files/figure-gfm/prob1.plot1-1.png" width="90%" />
DONE

First we want to take the count of the product names (how many times
each item is ordered), then rank the product names based on their total
count:

``` r
table_popitems = instacart %>% 
  filter(aisle == "baking ingredients" | aisle == "dog food care" | aisle == "packaged vegetables fruits") %>%
  group_by(aisle) %>%
  count(product_name, name = "n_prod") %>% 
  filter(dense_rank(desc(n_prod)) < 4) %>% 
  arrange(desc(n_prod)) %>% 
  rename (
  "Aisle" = aisle,
  "Product Name" = product_name,
  "Number of Times Ordered" = n_prod) %>% 
  knitr::kable()
```

NOT DONE: Change capital text for aisle

``` r
table_meanhr = instacart %>% 
  filter(product_name == "Pink Lady Apples" | product_name == "Coffee Ice Cream") %>% 
  mutate(
    order_dow = recode(order_dow, "0" = "Sunday", "1" = "Monday", "2" = "Tuesday", 
                       "3" = "Wednesday", "4" = "Thursday", "5" = "Friday", "6" = "Saturday"),
    order_dow = ordered(order_dow, c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))                   
    ) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hrordered = round(mean(order_hour_of_day), digits = 2)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hrordered
  ) %>% 
  rename ("Product Name" = product_name) %>% 
  knitr::kable()
```

NOT DONE: :( convert from decimal times to real times with splitting,
converting, then concactenate

## Problem 2

Data cleaning:

``` r
data("brfss_smart2010") 
force(brfss_smart2010)
```

    ## # A tibble: 134,203 x 23
    ##     Year Locationabbr Locationdesc Class Topic Question Response
    ##    <int> <chr>        <chr>        <chr> <chr> <chr>    <chr>   
    ##  1  2010 AL           AL - Jeffer… Heal… Over… How is … Excelle…
    ##  2  2010 AL           AL - Jeffer… Heal… Over… How is … Very go…
    ##  3  2010 AL           AL - Jeffer… Heal… Over… How is … Good    
    ##  4  2010 AL           AL - Jeffer… Heal… Over… How is … Fair    
    ##  5  2010 AL           AL - Jeffer… Heal… Over… How is … Poor    
    ##  6  2010 AL           AL - Jeffer… Heal… Fair… Health … Good or…
    ##  7  2010 AL           AL - Jeffer… Heal… Fair… Health … Fair or…
    ##  8  2010 AL           AL - Jeffer… Heal… Heal… Do you … Yes     
    ##  9  2010 AL           AL - Jeffer… Heal… Heal… Do you … No      
    ## 10  2010 AL           AL - Jeffer… Heal… Unde… Adults … Yes     
    ## # … with 134,193 more rows, and 16 more variables: Sample_Size <int>,
    ## #   Data_value <dbl>, Confidence_limit_Low <dbl>,
    ## #   Confidence_limit_High <dbl>, Display_order <int>,
    ## #   Data_value_unit <chr>, Data_value_type <chr>,
    ## #   Data_Value_Footnote_Symbol <chr>, Data_Value_Footnote <chr>,
    ## #   DataSource <chr>, ClassId <chr>, TopicId <chr>, LocationID <chr>,
    ## #   QuestionID <chr>, RESPID <chr>, GeoLocation <chr>

``` r
brfss_smart2010 = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(
    topic == "Overall Health",
    response == "Excellent" | response == "Very good" | response == "Good" | response == "Fair" | response == "Poor") %>% 
  mutate(response = ordered(response, c("Poor", "Fair", "Good", "Very good", "Excellent")))
```

DONE

``` r
seven_2002 = brfss_smart2010 %>% 
  filter(year == "2002") %>% 
  separate(locationdesc, into = c("state", "county"), sep = 4) %>% 
  select(-c("state")) %>% 
  rename("state" = locationabbr) %>% 
  group_by(state) %>%
  summarize(n_loc = n_distinct(county)) %>% 
  filter(n_loc > 6) %>% 
  arrange(desc(n_loc)) 


seven_2010 = brfss_smart2010 %>% 
  filter(year == "2010") %>% 
  separate(locationdesc, into = c("state", "county"), sep = 4) %>% 
  select(-c("state")) %>% 
  rename("state" = locationabbr) %>% 
  group_by(state) %>%
  summarize(n_loc = n_distinct(county)) %>% 
  filter(n_loc > 6) %>% 
  arrange(desc(n_loc)) 
```

In 2002, CT, FL, MA, NC, NJ, and PA were observed at 7 or more
locations. In 2010, CA, CO, FL, MA, MD, NC, NE, NJ, NY, OH, PA, SC, TX,
and WA were observed at 7 or more locations.

Do in-line R for this?

``` r
spaghetti = brfss_smart2010 %>% 
  filter(response == "Excellent") %>% 
  separate(locationdesc, into = c("state", "county"), sep = 4) %>% 
  select(-c("state")) %>% 
  rename("state" = locationabbr) %>% 
  group_by(year, state) %>% 
  mutate(avg_dv = mean(data_value)) %>% 
  select(year, state, avg_dv) %>%
  ggplot(aes(x = year, y = avg_dv, color = state)) + 
  geom_line() +
  labs(
    title = "Average Percentage of Respondents Rating General Health As 'Excellent' Over Time Across Locations Within Each State",
    x = "Year",
    y = "Average Percentage of Respondents Rating General Health As 'Excellent'",
    color = "State") +
  theme(plot.title = element_text(hjust = 0.8),
        legend.position = "right")

spaghetti
```

<img src="p8105_hw3_at3346_files/figure-gfm/prob2.3.plot1-1.png" width="90%" />
DONE

``` r
two_panel_scat = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(
    response == "Excellent" | response == "Very good" | response == "Good" | response == "Fair" | response == "Poor",
    year == "2006" | year == "2010",
    locationabbr == "NY") %>% 
  mutate(response = ordered(response, c("Poor", "Fair", "Good", "Very good", "Excellent"))) %>% 
  separate(locationdesc, into = c("state", "county"), sep="-") %>% 
  select(-c("locationabbr")) %>% 
  group_by(year, county, response) %>% 
  mutate(avg_dv = mean(data_value)) %>% 
  select(year, state, county, response, avg_dv) %>% 
  ggplot(aes(x = county, y = avg_dv, color = response, group = response)) + 
  geom_point() +
  geom_smooth(se = FALSE) +
  facet_grid(~year) +
  labs(
    title = "Distribution of Data Values For Responses Among Locations in NY State",
    x = "County in NY",
    y = "Average Data Value",
    color = "Response") +
  theme(plot.title = element_text(hjust = 0.5),
        axis.text.x = element_text(angle = 90, hjust = 1),
        panel.spacing = unit(1, "lines"),
        panel.border = element_rect(color = "black", fill = NA, size = 0.75))

two_panel_scat
```

    ## `geom_smooth()` using method = 'loess' and formula 'y ~ x'

<img src="p8105_hw3_at3346_files/figure-gfm/prob2.plot2-1.png" width="90%" />

## Problem 3

Load, tidy, and wrangle data:

``` r
accel_data = 
  read_csv("./data/accel_data.csv", col_names = TRUE) %>%
  janitor::clean_names() %>%
  mutate(
    weekend = recode(day, "Saturday" = 1, "Sunday" = 1, "Monday" = 0, "Tuesday" = 0, "Wednesday" = 0, "Thursday" = 0, "Friday" = 0),
    weekday = recode(day, "Saturday" = 0, "Sunday" = 0, "Monday" = 1, "Tuesday" = 1, "Wednesday" = 1, "Thursday" = 1, "Friday" = 1),
    day = ordered(day, c("Saturday", "Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday")),
    week = ordered(week, c("1", "2", "3", "4", "5"))) %>% 
  select(week, day_id, day, weekend, weekday, everything()) %>% 
  pivot_longer(
    cols = starts_with("activity_"),
    names_to = "activity_minute_num",
    names_prefix = "activity_",
    values_to = "activity_counts") %>% 
  mutate(activity_minute_num = as.numeric(activity_minute_num))
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_double(),
    ##   day = col_character()
    ## )

    ## See spec(...) for full column specifications.

The `accel_data` dataset contains 50400 observations and 7 variables.
The 7 variables in the dataset are `week`, `day_id`, `day`, `weekend`,
`weekday`, `activity_minute_num`, and `activity_counts`.

DONE?

``` r
tot_act = accel_data %>% 
  group_by(week, day_id, day) %>% 
  summarize (total_min = sum(activity_counts)) %>%
  select(week, day_id, day, total_min)

knitr::kable(tot_act)
```

| week | day\_id | day       | total\_min |
| :--- | ------: | :-------- | ---------: |
| 1    |       1 | Friday    |  480542.62 |
| 1    |       2 | Monday    |   78828.07 |
| 1    |       3 | Saturday  |  376254.00 |
| 1    |       4 | Sunday    |  631105.00 |
| 1    |       5 | Thursday  |  355923.64 |
| 1    |       6 | Tuesday   |  307094.24 |
| 1    |       7 | Wednesday |  340115.01 |
| 2    |       8 | Friday    |  568839.00 |
| 2    |       9 | Monday    |  295431.00 |
| 2    |      10 | Saturday  |  607175.00 |
| 2    |      11 | Sunday    |  422018.00 |
| 2    |      12 | Thursday  |  474048.00 |
| 2    |      13 | Tuesday   |  423245.00 |
| 2    |      14 | Wednesday |  440962.00 |
| 3    |      15 | Friday    |  467420.00 |
| 3    |      16 | Monday    |  685910.00 |
| 3    |      17 | Saturday  |  382928.00 |
| 3    |      18 | Sunday    |  467052.00 |
| 3    |      19 | Thursday  |  371230.00 |
| 3    |      20 | Tuesday   |  381507.00 |
| 3    |      21 | Wednesday |  468869.00 |
| 4    |      22 | Friday    |  154049.00 |
| 4    |      23 | Monday    |  409450.00 |
| 4    |      24 | Saturday  |    1440.00 |
| 4    |      25 | Sunday    |  260617.00 |
| 4    |      26 | Thursday  |  340291.00 |
| 4    |      27 | Tuesday   |  319568.00 |
| 4    |      28 | Wednesday |  434460.00 |
| 5    |      29 | Friday    |  620860.00 |
| 5    |      30 | Monday    |  389080.00 |
| 5    |      31 | Saturday  |    1440.00 |
| 5    |      32 | Sunday    |  138421.00 |
| 5    |      33 | Thursday  |  549658.00 |
| 5    |      34 | Tuesday   |  367824.00 |
| 5    |      35 | Wednesday |  445366.00 |

``` r
trends_wk = tot_act %>% 
  ggplot(aes(x = day, y = total_min, color = week)) + 
  geom_point() +
  geom_smooth(se = FALSE) +
  facet_grid(~week) +
  labs(
    title = "Total daily activity over 5 weeks",
    x = "Day of the week",
    y = "Total activity per day (min)") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

trends_day = tot_act %>% 
  ggplot(aes(x = week, y = total_min, color = day)) + 
  geom_point() +
  geom_smooth(se = FALSE) +
  facet_grid(~day) +
  labs(
    title = "Total daily activity over 5 weeks",
    x = "Week",
    y = "Total activity per day (min)") 
```

Overall, there doesn’t seem to be any trends apparent. For weeks 1 and
2, the total activity per day (in minutes) is lowest on Mondays, then
gradually increases throughout the week into the weekend. In week 3, the
total activity per day (in minutes) remains relatively consistent on all
days of the week except for Monday, which has the highest total daily
activity. For weeks 4 and 5, there is the lowest total daily activity on
the weekends.

DONE?

``` r
avg_accel_data = accel_data %>% 
  group_by(day, activity_minute_num) %>% 
  summarize(avg_ct = mean(activity_counts)) %>% 
  ggplot(aes(x = activity_minute_num, y = avg_ct, color = day, group = day)) + 
  geom_smooth(alpha = 0.3, se = FALSE) +
  labs(
    title = "24-hour activity time courses for each day of the week over a 5-week period",
    x = "Minute Number",
    y = "Total activity count",
    color = "Day") +
  theme(plot.title = element_text(hjust = 0.5),
        legend.position = "right")

avg_accel_data
```

    ## `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = "cs")'

<img src="p8105_hw3_at3346_files/figure-gfm/prob3.plot1-1.png" width="90%" />
DONE? Also plot a general trend line over 35 days
